[project]
name = "llm-agent-protector"
version = "0.1.0"
description = "To protect LLM agents from prompt injection and prompt leak with Polymorphic Prompt"
readme = "README.md"
authors = [{ name="Zhilong Wang", email="izhilongwang@gmail.com" }]
license = "MIT"
keywords = ["llm", "prompt injection", "agent", "security", "openai", "protection"]
dependencies = []

[project.urls]
Homepage = "https://github.com/zhilongwang/LLMAgentProtector"
Issues = "https://github.com/zhilongwang/LLMAgentProtector/issues"

[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
packages = ["llmagentprotector"]
